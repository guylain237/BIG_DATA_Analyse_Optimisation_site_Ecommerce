import pandas as pd
from dotenv import load_dotenv
import os

# Charger les variables d'environnement √† partir du fichier .env
load_dotenv()

class DataProcessing:
    def __init__(self, datasets):
        self.datasets = datasets
        self.processed_path = os.getenv("PROCESSED_PATH")

        # Cr√©er le dossier s'il n'existe pas
        os.makedirs(self.processed_path, exist_ok=True)

    def is_data_already_processed(self):
        """
        V√©rifie si les fichiers nettoy√©s existent d√©j√†.
        """
        return all(os.path.exists(os.path.join(self.processed_path, f"{name}_processed.csv")) for name in self.datasets)

    def clean_data(self):
        """
        Nettoie les datasets en supprimant les doublons et en convertissant les timestamps.
        """
        if self.is_data_already_processed():
            print("‚úÖ Les fichiers nettoy√©s existent d√©j√†, traitement ignor√©.")
            return

        print("üõ† Initialisation du nettoyage des donn√©es...\n")

        for name, df in self.datasets.items():
            df.drop_duplicates(inplace=True)  # Suppression des doublons
            print(f"‚úÖ Tous les doublons du fichier {name} ont √©t√© supprim√©s.\n")

            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')  # Conversion des dates
                print(f"‚úÖ Les dates ont √©t√© converties au bon format dans le fichier {name}.\n")

            # Enregistrer le fichier nettoy√©
            processed_file_path = os.path.join(self.processed_path, f"{name}_processed.csv")
            df.to_csv(processed_file_path, index=False)
            print(f"üìÇ Le fichier {name} est enregistr√© dans : {processed_file_path}.\n")

        # Fusionner item_properties_part1 et item_properties_part2 si disponibles
        if 'item_properties_part1' in self.datasets and 'item_properties_part2' in self.datasets:
            combined_file_path = os.path.join(self.processed_path, "item_properties_combined_processed.csv")

            if os.path.exists(combined_file_path):
                print("‚úÖ Le fichier fusionn√© item_properties_combined existe d√©j√†, fusion ignor√©e.\n")
            else:
                item_properties_combined = pd.concat([self.datasets['item_properties_part1'], self.datasets['item_properties_part2']], ignore_index=True)
                item_properties_combined.drop_duplicates(inplace=True)
                print("‚úÖ Les fichiers item_properties_part1 et item_properties_part2 ont √©t√© fusionn√©s et les doublons supprim√©s.\n")

                # Enregistrer le fichier fusionn√©
                item_properties_combined.to_csv(combined_file_path, index=False)
                print(f"üìÇ Le fichier fusionn√© item_properties_combined est enregistr√© dans : {combined_file_path}.\n")

        print("üéâ Donn√©es nettoy√©es avec succ√®s !")

    def get_processed_data(self):
        """
        Charge et retourne les datasets nettoy√©s depuis le dossier 'processed'.
        """
        processed_data = {}
        for name in self.datasets:
            processed_file_path = os.path.join(self.processed_path, f"{name}_processed.csv")
        
            if os.path.exists(processed_file_path):
                processed_data[name] = pd.read_csv(processed_file_path)  # Charger la version nettoy√©e
            else:
                print(f"‚ö†Ô∏è Attention : Le fichier nettoy√© {processed_file_path} n'existe pas. Retour des donn√©es brutes.")
                processed_data[name] = self.datasets[name]  # Retourner les donn√©es brutes si le fichier n'existe pas
        
        return processed_data